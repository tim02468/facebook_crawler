{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import facebook\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import os\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long lived token （執行一次就可以）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 注意是user_token, 不是app_token\n",
    "token = 'token'\n",
    "graph = facebook.GraphAPI(access_token = token)\n",
    "app_id = 'your_app_id'\n",
    "app_secret = 'your_app_secret'\n",
    "extended_token = graph.extend_access_token(app_id, app_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 250 posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 每次requests會得到25篇貼文，將requests轉為dict，paging key中是另一個dict裡面包含previous, next分別只上一頁和下一頁\n",
    "response = requests.get('https://graph.facebook.com/v2.7/1455214321359069/feed?access_token=' + extended_token.get(\"access_token\"))\n",
    "json_data = json.loads(response.text)\n",
    "# 先將前25篇存入feed_data\n",
    "feed_data = list(json_data.get(\"data\"))\n",
    "# 往下翻9頁，並將結果存入feed_data\n",
    "for i in range(1, 10):\n",
    "    response = requests.get(json_data.get(\"paging\").get(\"next\"))\n",
    "    json_data = json.loads(url.text)\n",
    "    feed_data.extend(json_data.get(\"data\"))\n",
    "    print(len(feed_data)) # 全部篇數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得 post id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_id = list(i.get(\"id\").split(\"_\")[1] for i in feed_data)\n",
    "len(post_id) #  總篇數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用selenium進行爬蟲，先登入FB\n",
    "path = os.path.join(os.getcwd(), \"geckodriver\") # driver的位置要給對\n",
    "driver = webdriver.Firefox(executable_path = path)\n",
    "driver.get(\"https://www.facebook.com\")\n",
    "assert \"Facebook\" in driver.title\n",
    "user = \"user_account\"\n",
    "passw = \"user_password\"\n",
    "elem = driver.find_element_by_id(\"email\")\n",
    "elem.clear()\n",
    "elem.send_keys(user)\n",
    "elem = driver.find_element_by_id(\"pass\")\n",
    "elem.clear()\n",
    "elem.send_keys(passw)\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for picture href & download pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get post href\n",
    "def get_post_href(post_url, class_ = \"_4-eo _2t9n\"): # 發現主要照片連結位置被放在這個class\n",
    "    driver.get(url)\n",
    "    source = driver.page_source\n",
    "    soup = bs(source, \"html.parser\")\n",
    "    for link in soup.find_all(href = re.compile(\"facebook\"), class_ = class_):\n",
    "        if link.get(\"href\") is not None:\n",
    "            return link.get(\"href\")\n",
    "        else:\n",
    "            class_ = \"_4-eo _2t9n _50z9\" # 有一些在這裡面\n",
    "            for link in soup.find_all(href = re.compile(\"facebook\"), class_ = class_):\n",
    "                if link.get(\"href\") is not None:\n",
    "                    return link.get(\"href\")\n",
    "# get picture\n",
    "def get_picture(post_url):\n",
    "    link = get_post_href(post_url)\n",
    "    if link is not None:\n",
    "        driver.get(link)\n",
    "        source = driver.page_source\n",
    "        soup = bs(source, \"html.parser\")\n",
    "        for pic in soup.find_all(\"img\", {\"class\": \"spotlight\"}):\n",
    "            return pic.get(\"src\")\n",
    "# get post's pictures (70%)，原因是分享的貼文沒辦法抓到圖片，或是同時貼文超過一張照片也沒辦法，或是照片大小格式特殊\n",
    "# 這些要另外做處理有點麻煩，覺得用API去抓照片不是個好方法\n",
    "for i in range(0, len(post_id)):\n",
    "    url = \"https://www.facebook.com/1455214321359069/posts/\" + post_id[i]\n",
    "    pic_link = get_picture(url)\n",
    "    if pic_link is not None:\n",
    "        r = requests.get(pic_link, stream = True) # 下載圖片\n",
    "        with open('pic/'+str(i)+'.png', 'wb') as out_file: \n",
    "            shutil.copyfileobj(r.raw, out_file)\n",
    "        del r "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
